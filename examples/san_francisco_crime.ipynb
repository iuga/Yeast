{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Fanciscon Crime\n",
    "\n",
    "## Motivation\n",
    "\n",
    "From 1934 to 1963, San Francisco was infamous for housing some of the world's most notorious criminals on the inescapable island of Alcatraz. Today, the city is known more for its tech scene than its criminal past. But, with rising wealth inequality, housing shortages, and a proliferation of expensive digital toys riding BART to work, there is no scarcity of crime in the city by the bay.\n",
    "\n",
    "### Overview\n",
    "\n",
    "From Sunset to SOMA, and Marina to Excelsior, this dataset provides nearly 12 years of crime reports from across all of San Francisco's neighborhoods. Given time and location, you must predict the category of crime that occurred.\n",
    "\n",
    "### Approach\n",
    "\n",
    "We will apply a full Data Science Development life cycle composed of the following steps:\n",
    "\n",
    "- Data Wrangling to perform all the necessary actions to clean the dataset.\n",
    "- Feature Engineering to create additional variables from the existing.\n",
    "- Data Normalization and Data Transformation for preparing the dataset for the learning algorithms.\n",
    "- Training / Testing data creation to evaluate the performance of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Yeast imports\n",
    "from yeast import Recipe\n",
    "from yeast.steps import *\n",
    "from yeast.transformers import *\n",
    "from yeast.selectors import *\n",
    "\n",
    "# Machine Learning imports\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/sf_train.csv')\n",
    "test = pd.read_csv('../../data/sf_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cleaning recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = Recipe([\n",
    "    # Normalize all column names\n",
    "    CleanColumnNamesStep('snake'),\n",
    "    # This dataset contains 2323 duplicates that we should remove only on training set\n",
    "    DropDuplicateRowsStep(role='training'),\n",
    "    # Some Geolocation points are missplaced\n",
    "    # We will replace the outlying coordinates with the average coordinates\n",
    "    MutateStep({\n",
    "        'x': MapValues({-120.5: np.NaN}),\n",
    "        'y': MapValues({90: np.NaN})\n",
    "    }),\n",
    "    MeanImputeStep(['x', 'y']),\n",
    "    # Extract some features drom the date:\n",
    "    CastStep({'dates': 'datetime'}),\n",
    "    MutateStep({\n",
    "        'year': DateYear('dates'),\n",
    "        'quarter': DateQuarter('dates'),\n",
    "        'month': DateMonth('dates'),\n",
    "        'week': DateWeek('dates'),\n",
    "        'day': DateDay('dates'),\n",
    "        'hour': DateHour('dates'),\n",
    "        'minute': DateMinute('dates'),\n",
    "        'dow': DateDayOfWeek('dates'),\n",
    "        'doy': DateDayOfYear('dates')\n",
    "    }),\n",
    "    # Calculate the tenure: days(date - min(date)):\n",
    "    MutateStep({\n",
    "        'tenure': lambda df: (df['dates'] - df['dates'].min()).apply(lambda x: x.days)\n",
    "    }),\n",
    "    # Is it on a block?\n",
    "    MutateStep({\n",
    "        'is_block': StrContains('block', column='address', case=False)\n",
    "    }),\n",
    "    # Drop irrelevant Columns\n",
    "    DropColumnsStep(['dates', 'day_of_week']),\n",
    "    # Cast the numerical features\n",
    "    CastStep({\n",
    "        'is_block': 'integer'  # True and False to 1 and 0\n",
    "    }),\n",
    "    # Convert the category (target) into a numerical feature:\n",
    "    OrdinalEncoderStep('category', role='training'),\n",
    "    # Keep only numerical features\n",
    "    SelectStep(AllNumeric()),\n",
    "]).prepare(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baked_train = recipe.bake(train, role=\"training\")\n",
    "baked_test  = recipe.bake(test, role=\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>304544</th>\n",
       "      <th>158399</th>\n",
       "      <th>244432</th>\n",
       "      <th>514937</th>\n",
       "      <th>16967</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>-122.391</td>\n",
       "      <td>-122.468</td>\n",
       "      <td>-122.422</td>\n",
       "      <td>-122.403</td>\n",
       "      <td>-122.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>37.734</td>\n",
       "      <td>37.717</td>\n",
       "      <td>37.7416</td>\n",
       "      <td>37.7982</td>\n",
       "      <td>37.7692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2011</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "      <td>2008</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarter</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doy</th>\n",
       "      <td>67</td>\n",
       "      <td>96</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>2983</td>\n",
       "      <td>3743</td>\n",
       "      <td>3309</td>\n",
       "      <td>1860</td>\n",
       "      <td>4428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_block</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           304544   158399   244432   514937   16967 \n",
       "category       25       16       21       16        7\n",
       "x        -122.391 -122.468 -122.422 -122.403 -122.427\n",
       "y          37.734   37.717  37.7416  37.7982  37.7692\n",
       "year         2011     2013     2012     2008     2015\n",
       "quarter         1        2        1        1        1\n",
       "month           3        4        1        2        2\n",
       "week           10       14        4        6        8\n",
       "day             8        6       28        9       20\n",
       "hour           18       18        2        0       10\n",
       "minute          0       30       41       15       43\n",
       "dow             1        5        5        5        4\n",
       "doy            67       96       28       40       51\n",
       "tenure       2983     3743     3309     1860     4428\n",
       "is_block        0        1        1        1        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baked_train.sample(5).head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(baked_train.columns)-set(['category']))\n",
    "dtrain = xgb.DMatrix(\n",
    "    baked_train[features].values, \n",
    "    label=baked_train['category'], \n",
    "    feature_names=baked_train[features].columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.482818</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>2.485002</td>\n",
       "      <td>0.002041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.467268</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>2.469610</td>\n",
       "      <td>0.002145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.454027</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>2.456544</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.442648</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>2.445381</td>\n",
       "      <td>0.001881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.433441</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>2.436348</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mlogloss-mean  train-mlogloss-std  test-mlogloss-mean  \\\n",
       "10             2.482818            0.000661            2.485002   \n",
       "11             2.467268            0.000718            2.469610   \n",
       "12             2.454027            0.000752            2.456544   \n",
       "13             2.442648            0.001062            2.445381   \n",
       "14             2.433441            0.001282            2.436348   \n",
       "\n",
       "    test-mlogloss-std  \n",
       "10           0.002041  \n",
       "11           0.002145  \n",
       "12           0.002004  \n",
       "13           0.001881  \n",
       "14           0.001993  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 39,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "history = xgb.cv(\n",
    "    params=params, dtrain=dtrain, nfold=5, seed=42,\n",
    "    num_boost_round=15, stratified=True, verbose_eval=False\n",
    ")\n",
    "\n",
    "history.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model achieved **2.433441** 5-fold cross-validation score after 10 epochs and **2.436348** on the testing set while 2.49136 was the benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "A benefit of using gradient boosting is that after the boosted trees are constructed, it is relatively straightforward to retrieve importance scores for each attribute. Generally, importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params=params, dtrain=dtrain, num_boost_round=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- hour: 598\n",
      "- x: 649\n",
      "- y: 836\n",
      "- is_block: 383\n",
      "- dow: 35\n",
      "- minute: 626\n",
      "- tenure: 393\n",
      "- day: 51\n",
      "- doy: 61\n",
      "- year: 32\n"
     ]
    }
   ],
   "source": [
    "for feature, importance in model.get_score().items():\n",
    "    print(f'- {feature}: {importance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links & Resources\n",
    "\n",
    "- [SF-Crime Analysis & Prediction by @yannisp](https://www.kaggle.com/yannisp/sf-crime-analysis-prediction)\n",
    "- [Feature Importance and Feature Selection With XGBoost in Python](https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
